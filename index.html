
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Generative Image Dynamics">
  <meta name="keywords" content="Generative Image Dynamics">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Generative Image Dynamics</title>

  <link rel="icon" type="image/x-icon" href="static/favicon.ico">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/index.js"></script>
<style>
#interactive {
  position: relative;
  display: inline-block;
  width: 768px;
  aspect-ratio: 16/9;
  max-width: 100%;
}
#interactive canvas, #interactive svg, #interactive #glfailed {
  display: block;
  position: absolute;
  width: 100%;
  height: 100%;
  touch-action: none;
}
#interactive svg {
  pointer-events: none;
}
#interactive #glfailed {
  color: #f88;
  background: black;
  display: none;
}
.load img {
  width: 128px;
  height: 72px;
  margin-right: 4px;
}
</style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Generative Image Dynamics</h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://zhengqili.github.io/">Zhengqi Li</a>, </span>
            <span class="author-block">
              <a href="https://research.google/people/RichardTucker/">Richard Tucker</a>,
            </span>
            <span class="author-block">
              <a href="https://www.cs.cornell.edu/~snavely/">Noah Snavely</a>,
            </span>
            <span class="author-block">
              <a href="https://holynski.org/">Aleksander Holynski</a> </span>
            </span>

          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Google Research </span>
          </div>

          <!-- <h1 style="font-size:24px;font-weight:bold">CVPR 2023</h1> -->
          
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="static/pdfs/GenerativeImageDynamics.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/xxx"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="#demo"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
<svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2023 Fonticons, Inc. --><path d="M256 0c-25.3 0-47.2 14.7-57.6 36c-7-2.6-14.5-4-22.4-4c-35.3 0-64 28.7-64 64V261.5l-2.7-2.7c-25-25-65.5-25-90.5 0s-25 65.5 0 90.5L106.5 437c48 48 113.1 75 181 75H296h8c1.5 0 3-.1 4.5-.4c91.7-6.2 165-79.4 171.1-171.1c.3-1.5 .4-3 .4-4.5V160c0-35.3-28.7-64-64-64c-5.5 0-10.9 .7-16 2V96c0-35.3-28.7-64-64-64c-7.9 0-15.4 1.4-22.4 4C303.2 14.7 281.3 0 256 0zM240 96.1c0 0 0-.1 0-.1V64c0-8.8 7.2-16 16-16s16 7.2 16 16V95.9c0 0 0 .1 0 .1V232c0 13.3 10.7 24 24 24s24-10.7 24-24V96c0 0 0 0 0-.1c0-8.8 7.2-16 16-16s16 7.2 16 16v55.9c0 0 0 .1 0 .1v80c0 13.3 10.7 24 24 24s24-10.7 24-24V160.1c0 0 0-.1 0-.1c0-8.8 7.2-16 16-16s16 7.2 16 16V332.9c-.1 .6-.1 1.3-.2 1.9c-3.4 69.7-59.3 125.6-129 129c-.6 0-1.3 .1-1.9 .2H296h-8.5c-55.2 0-108.1-21.9-147.1-60.9L52.7 315.3c-6.2-6.2-6.2-16.4 0-22.6s16.4-6.2 22.6 0L119 336.4c6.9 6.9 17.2 8.9 26.2 5.2s14.8-12.5 14.8-22.2V96c0-8.8 7.2-16 16-16c8.8 0 16 7.1 16 15.9V232c0 13.3 10.7 24 24 24s24-10.7 24-24V96.1z"/></svg>
                  </span>
		
                  <span>Demo</span>
                </a>
              </span>
              <!-- Supp Link. -->
              <!-- <span class="link-block"> -->
<!--                 <a href="static/pdfs/supp.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Supp</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block"> -->
       <!--          <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a> -->
              <!-- </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <center>
      <video id="teaser" autoplay muted loop playsinline width="100%">
        <source src="static/videos/teaser_1080.mp4" type="video/mp4">
      </video>
      </center>
<div class="columns is-centered">
<div class="column is-centered is-two-thirds">
      <h3 class="subtitle has-text-centered">
        <font size="2">
        <span class="dnerf"> </span> 
        Our approach models an image-space prior on scene dynamics that can be used to turn a single image into a seamless looping video or an interactive dynamic scene.  </font>
      </h3>
</div>
</div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body nopadding">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="450px" width="auto">
            <source src="static/videos/rose_loop.mp4"
                    type="video/mp4">
          </video>
	<br>
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/fern_2_loop.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="450px" width="auto">
            <source src="static/videos/fern_loop.mp4"
                    type="video/mp4">
          </video>
	<br>
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/latern_2_loop.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="450px" width="auto">
            <source src="static/videos/wildflower_loop.mp4"
                    type="video/mp4">
          </video>
	<br>
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/yellow_loop.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="450px" width="auto">
            <source src="static/videos/sunflower_loop.mp4"
                    type="video/mp4">
          </video>
	<br>
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/glove_loop.mp4"
                    type="video/mp4">
          </video>
        </div>
        

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="450px" width="auto">
            <source src="static/videos/tree_0_loop.mp4"
                    type="video/mp4">
          </video>
	<br>
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/cloth_loop.mp4"
                    type="video/mp4">
          </video>
        </div>

<!--         <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="450px" width="auto">
            <source src="static/videos/cherryblossm_loop.mp4"
                    type="video/mp4">
          </video>
        </div>
 -->


        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="450px" width="auto">
            <source src="static/videos/Dandelion_loop.mp4"
                    type="video/mp4">
          </video> 
	<br>
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/chime_loop.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="450px" width="auto">
            <source src="static/videos/leaves_loop.mp4"
                    type="video/mp4">
          </video>
	<br>
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/candle_3_loop.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="450px" width="auto">
            <source src="static/videos/tree_1_loop.mp4"
                    type="video/mp4">
          </video>
	<br>
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/latern_loop.mp4"
                    type="video/mp4">
          </video>
        </div>

<!--         <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="450px" width="auto">
            <source src="static/videos/6133103-loop.mp4"
                    type="video/mp4">
          </video>
        </div> -->

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="450px" width="auto">
            <source src="static/videos/lotus_loop.mp4"
                    type="video/mp4">
          </video>
	<br>
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/candle_2_loop.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="450px" width="auto">
            <source src="static/videos/tree_2_loop.mp4"
                    type="video/mp4">
          </video>
	<br>
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/cat_loop.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="450px" width="auto">
            <source src="static/videos/flower_0_loop.mp4"
                    type="video/mp4">
          </video>
	<br>
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/socks_loop.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/grapes_loop.mp4"
                    type="video/mp4">
          </video>
	<br>
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/paper_loop.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/leaves_close_loop.mp4"
                    type="video/mp4">
          </video>
	<br>
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/candle_0.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>


    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body nopadding">
    <div class="container">
 


 
 
<!-- 
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay playsinline muted loop height="288px">
            <source src="static/videos/pink-rose_loop.mp4"
                    type="video/mp4">
          </video>
        </div> -->

 





      </div>
      <h3 class="subtitle has-text-centered">
        <font size="2">
        <span class="dnerf"> </span> 
        Our method automatically turns single still images into seamless looping videos. </font>
      </h3>

    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
We present an approach to modeling an image-space prior on scene dynamics. Our prior is learned from a collection of motion trajectories extracted from real video sequences containing natural, oscillating motion such as trees, flowers, candles, and clothes blowing in the wind. Given a single image, our trained model uses a frequency-coordinated diffusion sampling process to predict a per-pixel long-term motion representation in the Fourier domain, which we call a neural stochastic motion texture. This representation can be converted into dense motion trajectories that span an entire video. Along with an image-based rendering module, these trajectories can be used for a number of downstream applications, such as turning still images into seamlessly looping dynamic videos, or allowing users to realistically interact with objects in real pictures. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

<br>
<section>
<br>

<div id="wrapper" style="text-align:center;"> 
    <video autoplay muted loop playsinline id="result_video_side" width="auto" > 
        <source type="video/mp4" src="static/videos/InterativeDynamics.mp4" /> 
    </video>
<!-- 
    <video autoplay muted loop playsinline id="result_video_side"> 
        <source type="video/mp4" src="static/videos/000654_side-0-1.mp4" /> 
    </video>
    <video  autoplay muted loop playsinline id="result_video_side"> 
        <source type="video/mp4" src="static/videos/000242_side-0-1.mp4" /> 
    </video> -->
    <div class="clear"></div>
    With stochastic motion textures, we can simulate response of object dynamics to an interactive user excitation.
</div>
<br>
<br>
<div class="columns is-centered has-text-centered">

<svg xmlns="http://www.w3.org/2000/svg" height="2em" viewBox="0 0 384 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2023 Fonticons, Inc. --><style>svg{fill:#ffdf0f}</style><path d="M0 256L28.5 28c2-16 15.6-28 31.8-28H228.9c15 0 27.1 12.1 27.1 27.1c0 3.2-.6 6.5-1.7 9.5L208 160H347.3c20.2 0 36.7 16.4 36.7 36.7c0 7.4-2.2 14.6-6.4 20.7l-192.2 281c-5.9 8.6-15.6 13.7-25.9 13.7h-2.9c-15.7 0-28.5-12.8-28.5-28.5c0-2.3 .3-4.6 .9-6.9L176 288H32c-17.7 0-32-14.3-32-32z"/></svg>
 </span><h2 class="title is-3">&nbsp; Try it yourself! &nbsp;</h2>                
<a id="demo"></a>
                <svg xmlns="http://www.w3.org/2000/svg" height="2em" viewBox="0 0 384 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2023 Fonticons, Inc. --><path d="M0 256L28.5 28c2-16 15.6-28 31.8-28H228.9c15 0 27.1 12.1 27.1 27.1c0 3.2-.6 6.5-1.7 9.5L208 160H347.3c20.2 0 36.7 16.4 36.7 36.7c0 7.4-2.2 14.6-6.4 20.7l-192.2 281c-5.9 8.6-15.6 13.7-25.9 13.7h-2.9c-15.7 0-28.5-12.8-28.5-28.5c0-2.3 .3-4.6 .9-6.9L176 288H32c-17.7 0-32-14.3-32-32z"/></svg> 
</div>
<div class="columns is-centered has-text-centered">
Click and drag a point on the image blow, release to see how the scene moves!
</div>

<!-- Begin demo -->
<center>
<div id="interactive" class="hero">
<canvas id="canvas" width="512" height="288"></canvas>
<div id=glfailed><br><br>[Demo requires browser with WebGL2 support.]</div>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 288" fill="none"><path id="arrowpath" stroke="white" stroke-width="3" fill="none" d=""></path><circle id="targetpoint" cx="-300" cy="0" r="5" fill="#08f" stroke="white" stroke-width="2"></circle></svg>
</div>

<br> 
Try a different image by clicking on the icons below:
<div class="load">
 <img src="static/images/rose/image.png" data-folder="rose"><img src="static/images/flower/image.png" data-folder="flower"><img src="static/images/tree2/image.png" data-folder="tree2">
</div>
</center>

<br>
<br>

<script>
// === GLOBALS ===
let canvas;
let gl;

// === SETTINGS ===

const PI = Math.PI;

// === SHADERS & PROGRAMS ===

const vertexShaders = {
  'pointwarp': {
    attribute: ['xy', 'flows_0123', 'flows_4567', 'flows_89ab', 'flows_cdef'],
    uniform: [
        'flows',
        'phi_0', 'phi_1', 'phi_2', 'phi_3', 'phi_4', 'phi_5', 'phi_6', 'phi_7',
        'phi_8', 'phi_9', 'phi_a', 'phi_b', 'phi_c', 'phi_d', 'phi_e', 'phi_f'],
    src: `#version 300 es
      in vec2 xy;
      in uvec4 flows_0123;
      in uvec4 flows_4567;
      in uvec4 flows_89ab;
      in uvec4 flows_cdef;
      out vec2 uv;
      uniform mediump vec4 phi_0;
      uniform mediump vec4 phi_1;
      uniform mediump vec4 phi_2;
      uniform mediump vec4 phi_3;
      uniform mediump vec4 phi_4;
      uniform mediump vec4 phi_5;
      uniform mediump vec4 phi_6;
      uniform mediump vec4 phi_7;
      uniform mediump vec4 phi_8;
      uniform mediump vec4 phi_9;
      uniform mediump vec4 phi_a;
      uniform mediump vec4 phi_b;
      uniform mediump vec4 phi_c;
      uniform mediump vec4 phi_d;
      uniform mediump vec4 phi_e;
      uniform mediump vec4 phi_f;

      // xr, yr, xi, yi – low byte first.
      vec4 decode(uint i) {
        return vec4(
          float(i & 0xffu) / 128.0 - 1.0,
          float((i>>8) & 0xffu) / 128.0 - 1.0,
          float((i>>16) & 0xffu) / 128.0 - 1.0,
          float((i>>24) & 0xffu) / 128.0 - 1.0);
      }

      void main(void) {
        float x = (xy.x + 0.5) / 512.0;
        float y = 1.0 - (xy.y + 0.5) / 288.0;
        uv = vec2(x, 1.0 - y);
        // Each phi is real_x, real_y, imaginary_x, imaginary_y, and each flow int32 is
        // in the same order
        vec4 flow = decode(flows_0123.r) * phi_0 + decode(flows_0123.g) * phi_1
                  + decode(flows_0123.b) * phi_2 + decode(flows_0123.a) * phi_3
                  + decode(flows_4567.r) * phi_4 + decode(flows_4567.g) * phi_5
                  + decode(flows_4567.b) * phi_6 + decode(flows_4567.a) * phi_7
                  + decode(flows_89ab.r) * phi_8 + decode(flows_89ab.g) * phi_9
                  + decode(flows_89ab.b) * phi_a + decode(flows_89ab.a) * phi_b
                  + decode(flows_cdef.r) * phi_c + decode(flows_cdef.g) * phi_d
                  + decode(flows_cdef.b) * phi_e + decode(flows_cdef.a) * phi_f;
        float flow_x = (flow.x - flow.z) / 256.0;
        float flow_y = (flow.y - flow.w) / 144.0;
        float flow_norm = flow_x * flow_x + flow_y * flow_y;
        float z = -flow_norm;
        x = x * 2.0 - 1.0;
        y = y * 2.0 - 1.0;
        gl_Position = vec4(x + flow_x, y - flow_y, z, 1.0);
      }`
  },
}

const fragmentShaders = {
  'f': {
    uniform: ['image'],
    src: `#version 300 es
      in mediump vec2 uv;
      uniform sampler2D image;
      out mediump vec4 fragColor;

      void main(void) {
        mediump vec4 c = texture(image, uv);
        fragColor = c;
      }`
  },
}

const programs = {
  'pointwarp': ['pointwarp', 'f'],
};



// === WEBGL SETUP ===

function initShaders(shaders, type) {
  for (let i in shaders) {
    const s = gl.createShader(type);
    const shader = shaders[i];
    gl.shaderSource(s, shader.src);
    gl.compileShader(s);
    if (!gl.getShaderParameter(s, gl.COMPILE_STATUS)) {
      console.log('Compiling ' + i, gl.getShaderInfoLog(s));
    }
    shader.shader = s;
    if (!shader.uniform) {
      shader.uniform = [];
    }
    if (!shader.attribute) {
      shader.attribute = [];
    }
  }
  console.log('Shaders compiled.');
}

function initPrograms(vertexShaders, fragmentShaders, programs) {
  for (let i in programs) {
    const p = gl.createProgram();
    const vertex = vertexShaders[programs[i][0]];
    const fragment = fragmentShaders[programs[i][1]];
    gl.attachShader(p, vertex.shader);
    gl.attachShader(p, fragment.shader);
    gl.linkProgram(p);
    if (!gl.getProgramParameter(p, gl.LINK_STATUS)) {
      console.log('Linking ' + i, gl.getProgramInfoLog(p));
    }
    const attribute = {};
    const uniform = {};
    vertex.attribute.concat(fragment.attribute).forEach((a) => {
      attribute[a] = gl.getAttribLocation(p, a);
    });
    vertex.uniform.concat(fragment.uniform).forEach((u) => {
      uniform[u] = gl.getUniformLocation(p, u);
    });
    programs[i].program = p;
    programs[i].attribute = attribute;
    programs[i].uniform = uniform;
  }
  console.log('Programs inited.');
}

function glFailed() {
  document.getElementById('glfailed').style.display = "block";
}

function init() {
  canvas = document.getElementById('canvas');
  gl = canvas.getContext('webgl2', {antialias: false, alpha: false});
  if (!gl) {
    glFailed();
  }
  initShaders(vertexShaders, gl.VERTEX_SHADER);
  initShaders(fragmentShaders, gl.FRAGMENT_SHADER);
  initPrograms(vertexShaders, fragmentShaders, programs);
}

init();

let remaining_to_load = 0;
function loadTexture(url) {
  const t = gl.createTexture();
  const image = new Image();
  image.onload = function() {
    gl.bindTexture(gl.TEXTURE_2D, t);
    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
    remaining_to_load--;
  }
  remaining_to_load++;
  image.src = url;
  return t;
}

function pointArray(width, height, border) {
  const columns = width + 2 * border;
  const rows = height + 2 * border;
  const data = new Float32Array((columns * rows) * 2);
  for (let x = 0; x < columns; x++) {
    for (let y = 0; y < rows; y++) {
      const idx = (y*columns + x) * 2;
      data[idx] = x - border;
      data[idx + 1] = y - border;
    }
  }
  const buffer = gl.createBuffer();
  gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
  gl.bufferData(gl.ARRAY_BUFFER, data, gl.STATIC_DRAW);
  return buffer;
}

function meshArray(width, height, border) {
  const columns = width + 2 * border;
  const rows = height + 2 * border;
  const size = (rows-1) * columns * 2;
  const data = new Uint32Array(size);
  let direction = 1;
  let idx = 0;
  for (let y = 0; y < rows-1; y++) {
    for (let x = 0; x < columns; x++) {
      let xx = x;
      if (direction < 0) {
        xx = columns - 1 - x;
      }
      data[idx] = y * columns + xx;
      data[idx+1] = (y + 1) * columns + xx;
      idx += 2; 
    }
    direction = -direction;
  }
  console.assert(idx == size);
  const buffer = gl.createBuffer();
  gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, buffer);
  gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, data, gl.STATIC_DRAW);
  return [buffer, size]
}

// If we use gl.INT attributes with four components we can send 16 bytes of data
// to the vertex shader in one attribute. With 4 attributes we can send 64 bytes.
// So if one byte encodes a number in the range (-128,127) (normalize to -1, 1)
// we can pack our 64 flow coefficients this way.
//
function clamp(i, base, limit) {
  return (i < base ? base : i >= limit ? limit-1 : i);
}
async function loadFlowCoefficients(file, width, height, border) {
  const frequencies = 16;
  const columns = width + 2 * border;
  const rows = height + 2 * border;
  const response = await fetch(file);
  const data = new Uint32Array(await response.arrayBuffer());
  console.assert(data.length == width * height * frequencies, 'Flow data is wrong size!');
  const padded = new Uint32Array(columns * rows * frequencies);
  // Copy data into padded with padding at border;
  for (let x = 0; x < columns; x++) {
    for (let y = 0; y < rows; y++) {
      const dx = clamp(x, border, width+border) - border;
      const dy = clamp(y, border, height+border) - border;
      const from = frequencies * (dy * width + dx);
      const to = frequencies * (y * columns + x);
      for (let i = 0; i < frequencies; i++) {
        padded[to + i] = data[from + i];
      }
    }
  }
  // Make the very edge always have zero.
  function zero(x, y) {
    const to = frequencies * (y * columns + x);
    for (let i = 0; i < frequencies; i++) {
      padded[to + i] = 0x80808080;
    }
  }
  for (let x = 0; x < columns; x++) {
    zero(x, 0);
    zero(x, rows-1);
  }
  for (let y = 0; y < rows; y++) {
    zero(0, y);
    zero(columns-1, y);
  }
  const buffer = gl.createBuffer();
  gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
  gl.bufferData(gl.ARRAY_BUFFER, padded, gl.STATIC_DRAW);
  return [data, buffer];
}

function glReset() {
  gl.enable(gl.DEPTH_TEST);
  gl.enable(gl.BLEND);
  gl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA);
  gl.depthFunc(gl.LEQUAL);
  console.log('reset');
}

glReset();

const all_scales = {
  rose: [
      811.0434532, 115.36923941, 63.62726212, 39.51707513,
      36.09076083, 26.24578261, 21.01270468, 26.08560528,
      23.15340153, 25.50192807, 65.31978774, 38.00659665,
      43.62371262, 55.01228421, 195.62246622, 54.19888583
  ],
  flower: [
      987.95284009, 73.41425321, 119.1790891, 51.5506267,
      39.01246448, 56.93307181, 49.79553268, 29.98144,
      18.90769313, 40.17826362, 48.75677635, 38.4140233,
      68.85882055, 55.3376773, 35.49130819, 16.33732716
  ],
  tree2: [
    240.20390244, 133.89857246, 96.93403143, 66.91954941, 67.28519664,
    63.38977511, 62.59354017, 111.60296899, 212.98846689, 268.27156353,
   397.19904949, 168.01954149, 65.93469411, 50.95328619, 52.01964568,
    47.4997937
  ],
}
const all_omega_scales = {
  rose: 2.0,
  flower: 3.0,
  tree2: 2.5
}
const all_force_scales = {
  rose: [1,1],
  flower: [1,1],
  tree2: [.5,.5],
}

function draw(data, state) {
  function phi(f) {
    const s = state.scales[f];
    const x = state.position_x[f] * state.omega[f] * s;
    const y = state.position_y[f] * state.omega[f] * s
    // If phase = 0, this is just [x, y, 0, 0];
    return [x * Math.cos(state.phase_x[f]), y * Math.cos(state.phase_y[f]), 
            -x * Math.sin(state.phase_x[f]), -y * Math.sin(state.phase_y[f]) ];
  }
  
  gl.clearColor(0.0, 0.0, 0.0, 1.0);
  gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

  const p = programs['pointwarp'];
  gl.bindBuffer(gl.ARRAY_BUFFER, data.points);
  gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, data.indices);

  gl.useProgram(p.program);
  gl.enableVertexAttribArray(p.attribute.xy);
  gl.vertexAttribPointer(p.attribute.xy, 2, gl.FLOAT, false, 8, 0);
  // 4 int-32s per buffer
  gl.bindBuffer(gl.ARRAY_BUFFER, data.flowbuffer);
  gl.enableVertexAttribArray(p.attribute.flows_0123);
  gl.vertexAttribIPointer(p.attribute.flows_0123, 4, gl.UNSIGNED_INT, 64, 0);
  gl.enableVertexAttribArray(p.attribute.flows_4567);
  gl.vertexAttribIPointer(p.attribute.flows_4567, 4, gl.UNSIGNED_INT, 64, 16);
  gl.enableVertexAttribArray(p.attribute.flows_89ab);
  gl.vertexAttribIPointer(p.attribute.flows_89ab, 4, gl.UNSIGNED_INT, 64, 32);
  gl.enableVertexAttribArray(p.attribute.flows_cdef);
  gl.vertexAttribIPointer(p.attribute.flows_cdef, 4, gl.UNSIGNED_INT, 64, 48);


  gl.activeTexture(gl.TEXTURE0);
  gl.bindTexture(gl.TEXTURE_2D, data.image);
  gl.uniform1i(p.uniform.image, 0);

  gl.uniform4fv(p.uniform.phi_0, phi(0));
  gl.uniform4fv(p.uniform.phi_1, phi(1));
  gl.uniform4fv(p.uniform.phi_2, phi(2));
  gl.uniform4fv(p.uniform.phi_3, phi(3));
  gl.uniform4fv(p.uniform.phi_4, phi(4));
  gl.uniform4fv(p.uniform.phi_5, phi(5));
  gl.uniform4fv(p.uniform.phi_6, phi(6));
  gl.uniform4fv(p.uniform.phi_7, phi(7));
  gl.uniform4fv(p.uniform.phi_8, phi(8));
  gl.uniform4fv(p.uniform.phi_9, phi(9));
  gl.uniform4fv(p.uniform.phi_a, phi(10));
  gl.uniform4fv(p.uniform.phi_b, phi(11));
  gl.uniform4fv(p.uniform.phi_c, phi(12));
  gl.uniform4fv(p.uniform.phi_d, phi(13));
  gl.uniform4fv(p.uniform.phi_e, phi(14));
  gl.uniform4fv(p.uniform.phi_f, phi(15));
  
  gl.drawElements(gl.TRIANGLE_STRIP, data.indexcount, gl.UNSIGNED_INT, 0);
}

const alpha = 0.8;
const beta = 0.05;

let data = {};
let state = {
  position_x:[], position_y:[], velocity_x:[], velocity_y:[],
  phase_x:[], phase_y:[],
  omega:[], omega_squared:[], damping:[],
  time:Date.now()
};

function calculate_omega(scale) {
  for (let f = 0; f < 16; f++) {
    state.omega[f] = scale * f * 30/76;  // Initial FFT frequencies for 5 second video @30fps.
    state.omega_squared[f] = state.omega[f] * state.omega[f];
    state.damping[f] = alpha + beta * state.omega_squared[f];
  }
}

function update(state) {
  // Only allow frame rates from 30 to 60fps.
  const time = Date.now();
  const dt = Math.max(Math.min((time - state.time)/1000, 1/30), 1/60);
  state.time = time;

  for (let f = 0; f < 16; f++) {
    const acceleration_x = -state.damping[f] * state.velocity_x[f] - state.omega_squared[f] * state.position_x[f];
    const acceleration_y = -state.damping[f] * state.velocity_y[f] - state.omega_squared[f] * state.position_y[f];
    state.position_x[f] += state.velocity_x[f] * dt;
    state.position_y[f] += state.velocity_y[f] * dt;
    state.velocity_x[f] += acceleration_x * dt;
    state.velocity_y[f] += acceleration_y * dt
  }
}

let t = 0;

function tick() {
  window.requestAnimationFrame(tick);
  if (remaining_to_load > 0) {
    return;
  }
  draw(data, state);
  if (!state.held) {
    update(state);
  }
}


async function load(folder) {
  const border = 16;
  remaining_to_load++;
  data.image = loadTexture(`static/images/${folder}/image.png`);
  data.points = pointArray(512, 288, border);
  gl.bindBuffer(gl.ARRAY_BUFFER, data.points);
  let buffersize = gl.getBufferParameter(gl.ARRAY_BUFFER, gl.BUFFER_SIZE);
  console.log('points', buffersize);
  [data.indices, data.indexcount] = meshArray(512, 288, border);
  gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, data.indices);
  buffersize = gl.getBufferParameter(gl.ELEMENT_ARRAY_BUFFER, gl.BUFFER_SIZE);
  console.log('indices', buffersize);
  [data.flow, data.flowbuffer] = await loadFlowCoefficients(`static/images/${folder}/flow_xy_data`, 512, 288, border);
  gl.bindBuffer(gl.ARRAY_BUFFER, data.flowbuffer);
  buffersize = gl.getBufferParameter(gl.ARRAY_BUFFER, gl.BUFFER_SIZE);
  console.log('flows', buffersize);
  state.scales = all_scales[folder];
  state.loading = false;
  console.log('Loaded', folder);

  for (let f = 0; f < 16; f++) {
    state.position_x[f] = 0;
    state.position_y[f] = 0;
    state.velocity_x[f] = 0;
    state.velocity_y[f] = 0;
    state.phase_x[f] = 0;
    state.phase_y[f] = 0;
  }
  calculate_omega(all_omega_scales[folder]);
  state.force_scale_x = all_force_scales[folder][0];
  state.force_scale_y = all_force_scales[folder][1];
  remaining_to_load--;
}



var pull_scale_posonly = 5e-5;

function hideArrow() {
  const a = document.querySelector('#arrowpath');
  const c = document.querySelector('#targetpoint');
  a.setAttribute('d', '');
  c.setAttribute('cx', -300);
}
function setArrow(x, y, ox, oy) {
  const t = document.querySelector('#targetpoint');
  const a = document.querySelector('#arrowpath');
  const omag = Math.sqrt(ox * ox + oy * oy);
  let ax = 0;
  let ay = 0
  if (omag > 0) {
    ax = (-ox + oy)/omag * 10;
    ay = (-oy - ox)/omag * 10;
  }
  a.setAttribute('d', `M ${x} ${y} l ${ox} ${oy} m ${ax} ${ay} l ${-ax} ${-ay} l ${ay} ${-ax}`);
  t.setAttribute('cx', x);
  t.setAttribute('cy', y);
}
function calculate_pull() {
  // Point at target_x, target_y has been dragged by relative amount offset_x, offset_y.
  const canvas_scale = canvas.getBoundingClientRect().width / 512;
  const x = Math.round(state.target_x / canvas_scale);
  const y = Math.round(state.target_y / canvas_scale);
  if (x < 0 || x >= 512 || y < 0 || y >= 288) {
    return;
  }
  let ox = state.offset_x / canvas_scale;
  let oy = state.offset_y / canvas_scale;
  const omag = Math.sqrt(ox * ox + oy * oy);
  if (omag == 0.0) {
    setArrow(x, y, 0, 0);
    for (let f = 1; f < 16; f++) {
      state.phase_x[f] = 0;
      state.phase_y[f] = 0;
      state.position_x[f] = 0;
      state.position_y[f] = 0;
      state.velocity_x[f] = 0;
      state.velocity_y[f] = 0;
    }
    return;
  }
  // Unit vector
  ox = ox / omag;
  oy = oy / omag;
  // sqrt to give a feeling of elastic resistance.
  const force = pull_scale_posonly * Math.sqrt(omag);

  // Get flow coefficients at the target pixel:
  const offset = 16 * (x + y * 512); // 64 bytes per pixel
  let move_x = 0;
  let move_y = 0;

  for (let f = 1; f < 16; f++) {
    const i = data.flow[offset + f];
    const s = state.scales[f];
    const xr = ((i & 0xff) / 128 - 1) * s;
    const yr = -(((i >> 8) & 0xff) / 128 - 1) * s;
    const xi = (((i >> 16) & 0xff) / 128 - 1) * s;
    const yi = -(((i >> 24) & 0xff) / 128 - 1) * s;

    state.phase_x[f] = 0;
    state.phase_y[f] = 0;

    // X and Y independent. Pick phase explicity to maximise offset,
    // because we're not going to use the imaginary part anyway in the ModalNerf
    // approach.
    // Dot product with offset vector.
    const dot_r = ox * xr + oy * yr;
    const dot_i = ox * xi + oy * yi;
    // Magnitude of dot product shows how far we can pull in
    // the given direction.
    const mag = Math.sqrt(dot_r * dot_r + dot_i * dot_i);
    const force_x = Math.abs(ox * mag * force) * state.force_scale_x;
    const force_y = Math.abs(oy * mag * force) * state.force_scale_y;
    // Set phase independently so each begins with max position,
    // depending on sign of ox/oy..
    state.phase_x[f] = Math.atan2(ox * xi, ox * xr);
    state.phase_y[f] = Math.atan2(oy * yi, oy * yr);
    state.position_x[f] = force_x / state.omega[f];
    state.position_y[f] = -force_y / state.omega[f];
    state.velocity_x[f] = 0;
    state.velocity_y[f] = 0;

    move_x += force_x * Math.sign(ox) * Math.sqrt(xr*xr + xi*xi);
    move_y += force_y * Math.sign(oy) * Math.sqrt(yr*yr + yi*yi);
  }
  setArrow(x + move_x, y + move_y, ox*omag - move_x, oy*omag - move_y);
}

// Drag to animate.

function addHandlers() {
  // An empty image
  const img = document.createElement("img");   
  img.src = "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7";
  const canvas = document.getElementById("canvas");
  canvas.addEventListener("pointerdown", (event) => {
    state.held = true;
    state.target_x = event.offsetX;
    state.target_y = event.offsetY;
    state.client_x = event.clientX;
    state.client_y = event.clientY;
    state.offset_x = 0;
    state.offset_y = 0;
    calculate_pull();
    canvas.setPointerCapture(event.pointerId);
  });
  canvas.addEventListener("pointermove", (event) => {
    if (state.held) {
      state.offset_x = event.clientX - state.client_x;
      state.offset_y = event.clientY - state.client_y;
      calculate_pull();
    }
  });
  canvas.addEventListener("pointerup", (event) => {
    state.held = false;
    hideArrow();
  });
  canvas.addEventListener("pointercancel", (event) => {
    state.held = false;
    hideArrow();
  });
  canvas.addEventListener("pointerout", (event) => {
    state.held = false;
    hideArrow();
  });
  canvas.addEventListener("pointerleave", (event) => {
    state.held = false;
    hideArrow();
  });
  document.querySelector('.load').addEventListener('click', (event) => {
    if (event.target.dataset && event.target.dataset.folder) {
      load(event.target.dataset.folder);
    }
  });
}

addHandlers();
load('rose');
tick();

</script>

<!-- End demo -->





<div id="wrapper" style="text-align:center;"> 
    <video autoplay muted loop playsinline id="result_video_side" height="640px" width="auto" > 
        <source type="video/mp4" src="static/videos/MotionMag.mp4" /> 
    </video>
<!-- 
    <video autoplay muted loop playsinline id="result_video_side"> 
        <source type="video/mp4" src="static/videos/000654_side-0-1.mp4" /> 
    </video>
    <video  autoplay muted loop playsinline id="result_video_side"> 
        <source type="video/mp4" src="static/videos/000242_side-0-1.mp4" /> 
    </video> -->
    <div class="clear"></div>
    We can minify (top) or magnify (bottom) animated motions by adjusting the amplitude of motion textures.
</div>
<br>

<div id="wrapper" style="text-align:center;"> 
    <video autoplay muted loop playsinline id="result_video_side" height="640px" width="auto" > 
        <source type="video/mp4" src="static/videos/slowmotion.mp4" /> 
    </video>
<!-- 
    <video autoplay muted loop playsinline id="result_video_side"> 
        <source type="video/mp4" src="static/videos/000654_side-0-1.mp4" /> 
    </video>
    <video  autoplay muted loop playsinline id="result_video_side"> 
        <source type="video/mp4" src="static/videos/000242_side-0-1.mp4" /> 
    </video> -->
    <div class="clear"></div>
    Slow-motion videos can be generated by interpolating predicted motion textures.
</div>
<br>
    <!-- Paper video. -->
<!--     <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <a id="overview_video"></a>
          <iframe src="https://www.youtube.com/embed/prrhosyJzIA" frameborder="0" allow="encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
     -->
    <!--/ Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths"><br><br>
        <h3 class="title is-3">Acknowledgements</h3>
        <div class="content has-text-justified">
          <p>
            Thanks to Rick Szeliski, Andrew Liu, Qianqian Wang, Boyang Deng, Xuan Luo, and Lucy Chai for helpful proofreading, comments and discussions.
        </div>
      </div>
    </div>

  </div>

</section>

 <br>



<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @inproceedings{li2023_GenerativeImageDynamics,
      title     = {Generative Image Dynamics},
      author    = {Li, Zhengqi and Tucker, Richard and Snavely, Noah and Holynski, Aleksander},
      year      = {2022}
    }</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div align="center" class="container">
<div class="columns is-centered">
        <div class="content">
            This website is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>. Thanks <a href="https://keunhong.com">Keunhong</a>!
        </div>
      </div>
    </div>
</footer>

</body>
</html>
